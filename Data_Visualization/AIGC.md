# LDM Latent Diffusion Model

### ÂèØËÉΩÁöÑÁîüÊàêÊµÅÁ®ãÂπ≤Ê∂âÊñπÊ≥ï

- PuLID ‰ºöÊèêÂèñÂèÇËÄÉÂõæÂÉè‰∏≠ÁöÑË∫´‰ªΩÁâπÂæÅÔºåÂπ∂Âú®ÁîüÊàêËøáÁ®ã‰∏≠Â∞ÜËøô‰∫õ‰ø°ÊÅØÊ≥®ÂÖ•Âà∞ÊΩúÂú®Ë°®Á§∫‰∏≠„ÄÇ
- Âú®ÂéüÊúâÁöÑÊâ©Êï£ÊµÅÁ®ã‰∏≠Â¢ûÂä†‰∏Ä‰∏™È¢ùÂ§ñÁöÑÂàÜÊîØÔºà‰æãÂ¶Ç Lightning T2I ÂàÜÊîØÔºâÔºåÈÄöËøáÂØπÊØîÂØπÈΩêÊäÄÊúØÂíåÈ¢ùÂ§ñÁöÑ ID ÊçüÂ§±ÔºåËøõ‰∏ÄÊ≠•Á°Æ‰øùÂõæÂÉèÁªÜËäÇÔºà‰æãÂ¶ÇÈù¢ÈÉ®ÁâπÂæÅÔºâ‰∏éÂèÇËÄÉÂõæÂÉè‰øùÊåÅ‰∏ÄËá¥Ôºå‰ªéËÄåÂáèÂ∞ëÂéüÂßãÊ®°ÂûãË°å‰∏∫Ë¢´Âπ≤Êâ∞ÁöÑÂèØËÉΩ„ÄÇ
- Âú®ÁîüÊàêÂô®Ôºà‰æãÂ¶ÇÁî®‰∫éÂéªÂô™ÁöÑ U-NetÔºâ‰∏≠ÔºåÂ∞ÜË∫´‰ªΩÂêëÈáè‰Ωú‰∏∫È¢ùÂ§ñÁöÑÊù°‰ª∂ËæìÂÖ•„ÄÇÈÄöÂ∏∏ÔºåËøô‰∏™ÂêëÈáèÂèØ‰ª•‰∏éÂô™Â£∞ÂêëÈáèÂú®Êüê‰∫õÂ±ÇËøõË°åÊãºÊé•ÊàñÈÄöËøáÁ∫øÊÄßÂèòÊç¢ÂêéËøõË°åÁõ∏Âä†
- Âú®‰∏Ä‰∫õÊ®°Âûã‰∏≠Ôºå‰ºöÂà©Áî®‰∫§ÂèâÊ≥®ÊÑèÂäõÂ±ÇÊù•Â∞ÜË∫´‰ªΩÁâπÂæÅ‚ÄúÂØπÈΩê‚ÄùÂà∞ÊΩúÂú®Ë°®Á§∫‰∏ä„ÄÇËøôÈáåÔºåË∫´‰ªΩÂêëÈáè‰Ωú‰∏∫‚ÄúÈîÆ‚ÄùÊàñ‚ÄúÂÄº‚ÄùÂèÇ‰∏éÊ≥®ÊÑèÂäõËÆ°ÁÆó„ÄÇ

### VAE Variational AutoEncoder

VAEÔºàÂèòÂàÜËá™ÁºñÁ†ÅÂô®ÔºåVariational AutoencoderÔºâÔºöÊòØ‰∏ÄÁßçÁîüÊàêÊ®°ÂûãÔºåÂÆÉÈÄöËøáÁºñÁ†ÅÂô®Â∞ÜÊï∞ÊçÆÊò†Â∞ÑÂà∞‰∏Ä‰∏™Ê¶ÇÁéáÂàÜÂ∏ÉÁöÑ Latent SpaceÔºåÂÜçÈÄöËøáËß£Á†ÅÂô®ÁîüÊàêÊñ∞ÁöÑÊï∞ÊçÆÔºå‰ΩøÂæóÁîüÊàêÁöÑÊï∞ÊçÆÊõ¥ÂÖ∑**ËøûË¥ØÊÄßÂíåÂ§öÊ†∑ÊÄß**„ÄÇ

---

### **1. Latent SpaceÔºàÊΩúÂú®Á©∫Èó¥Ôºâ**

Latent SpaceÔºàÊΩúÂú®Á©∫Èó¥ÔºâÊòØÂ∞ÜÈ´òÁª¥Êï∞ÊçÆÔºàÂ¶ÇÂõæÂÉè„ÄÅÊñáÊú¨ÔºâËΩ¨Êç¢‰∏∫‰ΩéÁª¥ÁöÑÂêëÈáèË°®Á§∫ÔºåÂêåÊó∂‰øùÁïôÊï∞ÊçÆÁöÑÂÖ≥ÈîÆÁâπÂæÅ„ÄÇ

- Âú®ÂõæÂÉèÁîüÊàê‰ªªÂä°‰∏≠Ôºå‰∏çÂêåÁöÑ‰∫∫ËÑ∏ÂèØ‰ª•Êò†Â∞ÑÂà∞‰∏Ä‰∏™ÊΩúÂú®Á©∫Èó¥ÁÇπÔºåËÄåËøô‰∏™ÁÇπÁöÑÂèòÂåñ‰ºöÂØºËá¥ËÑ∏ÈÉ®ÁâπÂæÅÔºàÂ¶ÇÂπ¥ÈæÑ„ÄÅË°®ÊÉÖÔºâÁöÑÂèòÂåñ„ÄÇ
- Âú® NLP ‰ªªÂä°‰∏≠ÔºåËØ≠‰πâÁõ∏ËøëÁöÑÂè•Â≠êÂèØËÉΩ‰ºöÊúâÁõ∏‰ººÁöÑÊΩúÂú®Ë°®Á§∫„ÄÇ

Âú®‰ΩéÁª¥Êï∞ÊçÆ‰∏≠ËøõË°åÊï∞ÊçÆÂ§ÑÁêÜÂèØ‰ª•ÊèêÈ´òËÆ°ÁÆóÊïàÁéá„ÄÇ  
Âú®ÊΩúÂú®Á©∫Èó¥ËøõË°åÊìç‰ΩúÔºàÂ¶ÇÊèíÂÄº„ÄÅÈááÊ†∑ÔºâÔºåÂèØ‰ª•ÁîüÊàêÊñ∞ÁöÑÊï∞ÊçÆ„ÄÇ  
ÊΩúÂú®Á©∫Èó¥ÂèØ‰ª•Â≠¶Âà∞Êï∞ÊçÆÁöÑÊ†∏ÂøÉÁªìÊûÑÔºå‰æãÂ¶ÇÂú®‰∫∫ËÑ∏Êï∞ÊçÆ‰∏≠ÔºåÂèØËÉΩÊúâ‰∏ÄÊù°‚ÄúÂπ¥ÈæÑ‚ÄùÊñπÂêëÊàñ‚ÄúÂæÆÁ¨ë‚ÄùÊñπÂêë„ÄÇ

---

### **2. VAEÔºàVariational AutoencoderÔºåÂèòÂàÜËá™ÁºñÁ†ÅÂô®Ôºâ**

VAE ÊòØ‰∏ÄÁßçÂü∫‰∫é **AutoencoderÔºàËá™ÁºñÁ†ÅÂô®Ôºâ** ÁöÑÁîüÊàêÊ®°ÂûãÔºåÂèØ‰ª•Â≠¶‰π†ÊΩúÂú®Á©∫Èó¥ÁöÑÊ¶ÇÁéáÂàÜÂ∏ÉÔºå‰ªéËÄåÁîüÊàêÊï∞ÊçÆ„ÄÇ

#### **(1) VAE ÁªìÊûÑ**

- **ÁºñÁ†ÅÂô®ÔºàEncoderÔºâ**ÔºöÂ∞ÜËæìÂÖ•Êï∞ÊçÆ $ x $ Êò†Â∞ÑÂà∞ÊΩúÂú®Á©∫Èó¥ $ z $Ôºå‰ΩÜÊòØ‰∏çÂêå‰∫éÊôÆÈÄöËá™ÁºñÁ†ÅÂô®ÔºåÂÆÉÂ≠¶‰π†ÁöÑÊòØ**‰∏Ä‰∏™ÂàÜÂ∏É**ÔºàÂùáÂÄº $ \mu $ ÂíåÊñπÂ∑Æ $ \sigma^2 $ÔºâÔºåËÄå‰∏çÊòØ‰∏Ä‰∏™Âõ∫ÂÆöÁöÑÁÇπÔºö
  $$
  q(z | x) = \mathcal{N}(\mu, \sigma^2)
  $$
- **Ëß£Á†ÅÂô®ÔºàDecoderÔºâ**Ôºö‰ªéÊΩúÂú®Á©∫Èó¥ÁöÑÈááÊ†∑ÁÇπ $ z $ ÁîüÊàêÊï∞ÊçÆ $ x' $ÔºåÂç≥Ôºö
  $$
  p(x | z)
  $$

#### **(2) ‰∏∫‰ªÄ‰πà VAE ÈúÄË¶ÅÂàÜÂ∏ÉÔºàËÄå‰∏çÊòØÊôÆÈÄöËá™ÁºñÁ†ÅÂô®ÔºâÔºü**

ÊôÆÈÄöÁöÑ Autoencoder Âè™Â≠¶‰π†‰∏Ä‰∏™Á°ÆÂÆöÁöÑÊΩúÂú®Ë°®Á§∫ $ z $ÔºåËÄå VAE ÈÄöËøáÂ≠¶‰π†ÂàÜÂ∏É $ \mathcal{N}(\mu, \sigma^2) $Ôºå‰ΩøÊΩúÂú®Á©∫Èó¥Êõ¥Âä†Âπ≥ÊªëÂíåËøûË¥ØÔºå‰ªéËÄåÂÖ∑Â§áÊõ¥Âº∫ÁöÑÁîüÊàêËÉΩÂäõ„ÄÇ‰æãÂ¶ÇÔºö

- **ÊôÆÈÄö Autoencoder**ÔºöËæìÂÖ•Êï∞ÊçÆÁÇπ A Âíå B ‰ºöË¢´ÁºñÁ†ÅÂà∞ÊΩúÂú®Á©∫Èó¥ÁöÑ‰∏§‰∏™ÁÇπ $ z_A $ Âíå $z_B $Ôºå‰ΩÜÂÆÉ‰ª¨‰πãÈó¥ÁöÑÂå∫ÂüüÂèØËÉΩÊ≤°ÊúâÊÑè‰πâÔºàÊó†Ê≥ïËß£Á†Å‰∏∫ÁúüÂÆûÊï∞ÊçÆÔºâ„ÄÇ
- **VAE**ÔºöËæìÂÖ• A Âíå B ‰ºöË¢´ÁºñÁ†ÅÂà∞‰∏§‰∏™È´òÊñØÂàÜÂ∏ÉÔºåËß£Á†ÅÂô®Â≠¶‰π†‰ªéËøô‰∫õÂàÜÂ∏É‰∏≠ÈááÊ†∑ÔºåÁ°Æ‰øùÊΩúÂú®Á©∫Èó¥ÁöÑ‰∏çÂêåÂå∫ÂüüÈÉΩËÉΩÁîüÊàêÊúâÊÑè‰πâÁöÑÊï∞ÊçÆ„ÄÇ

#### **(3) ËÆ≠ÁªÉÁõÆÊ†á**

VAE ÁöÑÊçüÂ§±ÂáΩÊï∞Áî±‰∏§ÈÉ®ÂàÜÁªÑÊàêÔºö

- **ÈáçÊûÑÊçüÂ§±ÔºàReconstruction LossÔºâ**Ôºö‰øùËØÅËß£Á†ÅÂô®ËÉΩÂ§üÂ∞ΩÂèØËÉΩËøòÂéüËæìÂÖ•Êï∞ÊçÆ„ÄÇ
  $$
  \mathbb{E}_{q(z|x)} [ \log p(x|z) ]
  $$
- **KL Êï£Â∫¶ÔºàKL DivergenceÔºâ**ÔºöÁ°Æ‰øùÊΩúÂú®ÂèòÈáè $ z $ Êé•ËøëÊ†áÂáÜÊ≠£ÊÄÅÂàÜÂ∏ÉÔºà$ \mathcal{N}(0, I) $Ôºâ„ÄÇ
  $$
  D_{KL}( q(z | x) || p(z) )
  $$

ÊúÄÁªàÁöÑÁõÆÊ†áÊòØ **ÊúÄÂ∞èÂåñÊÄªÊçüÂ§±**Ôºö

$$
L = \mathbb{E}_{q(z|x)} [ \log p(x|z) ] - D_{KL}( q(z | x) || p(z) )
$$

---

### **3. VAE ÁöÑ‰ΩúÁî®**

**VAE** ÈÄöËøáÁºñÁ†ÅÊï∞ÊçÆÂà∞Ê¶ÇÁéáÂàÜÂ∏ÉÔºå‰ΩøÂæóÊΩúÂú®Á©∫Èó¥Êõ¥Âä†Âπ≥ÊªëÔºåËÉΩÂ§üÁîüÊàêÊñ∞Êï∞ÊçÆÔºåÂπ∂ÊúâÊïàËøõË°åÊï∞ÊçÆÊèíÂÄº„ÄÇÈÄÇÁî®‰∫éÂõæÂÉèÁîüÊàê„ÄÅÈ£éÊ†ºËøÅÁßª„ÄÅÂºÇÂ∏∏Ê£ÄÊµãÁ≠â‰ªªÂä°„ÄÇ

1. **Êï∞ÊçÆÁîüÊàê**ÔºöÂèØ‰ª•ÁîüÊàêÁ±ª‰ºº‰∫éËÆ≠ÁªÉÊï∞ÊçÆÁöÑÊñ∞Ê†∑Êú¨ÔºàÂ¶Ç‰∫∫ËÑ∏„ÄÅÊâãÂÜôÊï∞Â≠óÔºâ„ÄÇ
2. **Êï∞ÊçÆÊèíÂÄº**ÔºöÂú®ÊΩúÂú®Á©∫Èó¥‰∏≠ÊèíÂÄºÔºåÂèØ‰ª•ÂÆûÁé∞È£éÊ†ºËøÅÁßªÊàñÂπ≥ÊªëÂèòÂåñÔºåÂ¶ÇËÆ©‰∏ÄÂº†ËÑ∏ÈÄêÊ∏êÂèòËÄÅ„ÄÇ
3. **ÈôçÂô™‰∏éÁâπÂæÅÂ≠¶‰π†**ÔºöVAE ÂÖ∑Êúâ Autoencoder ÁöÑÁâπÊÄßÔºåÂèØ‰ª•Áî®Êù•Â≠¶‰π†Êï∞ÊçÆÁöÑÊ†∏ÂøÉÁâπÂæÅ„ÄÇ

---

VAE Ê®°ÂûãÁªìÊûÑÁ§∫‰æãÔºö

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class VAE(nn.Module):
    def __init__(self, input_dim=784, hidden_dim=400, latent_dim=20):
        super(VAE, self).__init__()
        # ÁºñÁ†ÅÂô®ÈÉ®ÂàÜÔºöÂ∞ÜËæìÂÖ•Êò†Â∞ÑÂà∞ÈöêËóèÂ±ÇÔºåÂÜçÊò†Â∞ÑÂà∞ÊΩúÂú®Á©∫Èó¥ÁöÑÂùáÂÄºÂíåÂØπÊï∞ÊñπÂ∑Æ
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.fc_mu = nn.Linear(hidden_dim, latent_dim)      # ÂùáÂÄº
        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)  # ÂØπÊï∞ÊñπÂ∑Æ

        # Ëß£Á†ÅÂô®ÈÉ®ÂàÜÔºöÂ∞ÜÈááÊ†∑ÁöÑÊΩúÂú®ÂèòÈáèÊò†Â∞ÑÂõûÂéüÂßãÊï∞ÊçÆÁ©∫Èó¥
        self.fc2 = nn.Linear(latent_dim, hidden_dim)
        self.fc3 = nn.Linear(hidden_dim, input_dim)

    def encode(self, x):
        h1 = F.relu(self.fc1(x))
        mu = self.fc_mu(h1)
        logvar = self.fc_logvar(h1)
        return mu, logvar

    def reparameterize(self, mu, logvar):
        # ‰ΩøÁî®ÈáçÂèÇÊï∞ÂåñÊäÄÂ∑ßËøõË°åÈááÊ†∑Ôºå‰øùËØÅÁΩëÁªúÂèØÂæÆÂàÜ
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std

    def decode(self, z):
        h2 = F.relu(self.fc2(z))
        return torch.sigmoid(self.fc3(h2))

    def forward(self, x):
        # Â±ïÂπ≥ËæìÂÖ•ÔºåÂπ∂ÁºñÁ†Å‰∏∫ÊΩúÂú®ÂèòÈáèÂèÇÊï∞
        mu, logvar = self.encode(x.view(-1, 784))
        # ÈááÊ†∑ÊΩúÂú®ÂèòÈáè
        z = self.reparameterize(mu, logvar)
        # Ëß£Á†ÅÂæóÂà∞ÈáçÊûÑÁªìÊûú
        recon_x = self.decode(z)
        return recon_x, mu, logvar
```

### ‰ª£Á†ÅËØ¥Êòé

1. **ÁºñÁ†ÅÂô®ÈÉ®ÂàÜ**

   - ËæìÂÖ•Êï∞ÊçÆÈÄöËøá `fc1` ÂÖ®ËøûÊé•Â±ÇÊò†Â∞ÑÂà∞ÈöêËóèÂ±ÇÔºåÂπ∂‰ΩøÁî® ReLU ÊøÄÊ¥ªÂáΩÊï∞„ÄÇ
   - ÈöêËóèÂ±ÇÁöÑËæìÂá∫ÂàÜÂà´ÈÄöËøá `fc_mu` Âíå `fc_logvar` ÂæóÂà∞ÊΩúÂú®Á©∫Èó¥ÁöÑÂùáÂÄº $ \mu $ ÂíåÂØπÊï∞ÊñπÂ∑Æ $ \log \sigma^2 $„ÄÇ

2. **ÈáçÂèÇÊï∞ÂåñÈááÊ†∑**

   - ÈÄöËøá `reparameterize` ÂáΩÊï∞ÔºåÂ∞Ü $ \mu $ Âíå $ \log \sigma^2 $ ËΩ¨Êç¢‰∏∫Ê†áÂáÜÂ∑ÆÔºåÂπ∂Âà©Áî®ÈöèÊú∫Âô™Â£∞ $ \epsilon $ ËøõË°åÈááÊ†∑ÔºåÂæóÂà∞ÊΩúÂú®ÂèòÈáè $ z = \mu + \sigma \cdot \epsilon $„ÄÇ
   - Ëøô‰∏ÄÊìç‰Ωú‰ΩøÂæóÈááÊ†∑ËøáÁ®ã‰øùÊåÅÂèØÂæÆÔºå‰ªéËÄåÊîØÊåÅÂèçÂêë‰º†Êí≠„ÄÇ

3. **Ëß£Á†ÅÂô®ÈÉ®ÂàÜ**

   - ÊΩúÂú®ÂèòÈáè $ z $ ÁªèËøá `fc2` ÂÖ®ËøûÊé•Â±ÇÂíå ReLU ÊøÄÊ¥ªÔºåÂÜçÈÄöËøá `fc3` ÂÖ®ËøûÊé•Â±ÇÊò†Â∞ÑÂõûÂéüÂßãÊï∞ÊçÆÁ©∫Èó¥ÔºåÊúÄÂêé‰ΩøÁî® Sigmoid ÊøÄÊ¥ªÂáΩÊï∞ÔºàÈÄÇÁî®‰∫éÂÉè MNIST ËøôÁßçÂΩí‰∏ÄÂåñÂà∞ [0,1] ÁöÑÊï∞ÊçÆÔºâ„ÄÇ

4. **ÂâçÂêë‰º†Êí≠**
   - Âú® `forward` ÂáΩÊï∞‰∏≠ÔºåÈ¶ñÂÖàÂØπËæìÂÖ•Êï∞ÊçÆËøõË°åÂ±ïÂπ≥Â§ÑÁêÜÔºåÁÑ∂Âêé‰æùÊ¨°ÊâßË°åÁºñÁ†Å„ÄÅÈááÊ†∑ÂíåËß£Á†ÅÊìç‰ΩúÔºåÊúÄÁªàËæìÂá∫ÈáçÊûÑÁªìÊûú‰ª•ÂèäÊΩúÂú®ÂèòÈáèÂèÇÊï∞ $ \mu $ Âíå $ \log \sigma^2 $„ÄÇ

# Diffusion Transformer

ËøôÊòØ‰∏Ä‰∏™Âü∫‰∫é Latent Diffusion Model ÁöÑÊâ©Êï£ÊÄßÂõæË±°ÁîüÊàêÊ®°ÂûãÔºåÂèñ‰ª£‰∫ÜÂéüÂÖà Stable Diffusion ‰∏≠ÁöÑ UNet ÈÉ®‰ªΩ,Ê≠§ÊñπÊ≥ïÂü∫Êú¨ËÑ±ËÉé‰∫é Vision Transformer„ÄÇË∞ÉÊï¥‰∫ÜÂÖ∂‰∏≠ÁöÑ Layer Norm ÈÉ®‰ªΩÔºåÁî® Adaptive Layer Norm Âèñ‰ª£‰∫ÜÂéüÊù•ÁöÑ Layer Norm„ÄÇ[ËÆ∫ÊñáÈìæÊé•](https://arxiv.org/abs/2212.09748)

![](./DT.png)

## SPE

**ÊÄªÁªìÔºö**

**SPEÔºàSinusoidal Positional EncodingÔºâ** ÊòØÂú® Transformer Á≠âÊ®°Âûã‰∏≠‰ΩøÁî®ÁöÑ‰ΩçÁΩÆÁºñÁ†ÅÊñπÊ≥ïÔºåÁî®‰∫éÁªôÊ®°ÂûãÊèê‰æõ **Â∫èÂàó‰∏≠ÊØè‰∏™‰ΩçÁΩÆÁöÑ‰ø°ÊÅØ**„ÄÇ  
ÂÆÉÁöÑ‰ΩúÁî®ÊòØËÆ©Ê®°ÂûãÂú®Ê≤°ÊúâÂæ™ÁéØÁªìÊûÑÔºàÂ¶Ç RNNÔºâÊàñÂç∑ÁßØÁªìÊûÑÔºàÂ¶Ç CNNÔºâÁöÑÊÉÖÂÜµ‰∏ãÔºåËÉΩÂ§üÊÑüÁü•ËæìÂÖ•Â∫èÂàó‰∏≠ÂêÑ‰∏™ÂÖÉÁ¥†ÁöÑ**‰ΩçÁΩÆ‰ø°ÊÅØ**„ÄÇ

---

**ËØ¶ÁªÜËß£ÈáäÔºö**

### üß† ‰∏∫‰ªÄ‰πàÈúÄË¶Å Positional EncodingÔºü

Transformer Ëá™Ë∫´‰∏çÂÖ∑Â§áÂ§ÑÁêÜÂ∫èÂàóÈ°∫Â∫èÁöÑËÉΩÂäõÔºà‰∏çÂÉè RNN ÊúâÊó∂Èó¥Ê≠•Ê¶ÇÂøµÔºâ„ÄÇ  
ÊâÄ‰ª•Êàë‰ª¨ÈúÄË¶ÅÊòæÂºèÂú∞ÂëäËØâÊ®°ÂûãÔºö**‚ÄúÁ¨¨ 1 ‰∏™ËØç„ÄÅÁ¨¨ 2 ‰∏™ËØç‚Ä¶‚Ä¶ÂÆÉ‰ª¨Âú®Âè•Â≠ê‰∏≠ÁöÑ‰ΩçÁΩÆ‰∏çÂêå„ÄÇ‚Äù**

---

### üî¢ SPE ÁöÑÂéüÁêÜ

SPE ‰ΩøÁî®‰∏çÂêåÈ¢ëÁéáÁöÑÊ≠£Âº¶Âíå‰ΩôÂº¶ÂáΩÊï∞Êù•‰∏∫ÊØè‰∏™‰ΩçÁΩÆÁîüÊàêÂîØ‰∏ÄÁöÑÂêëÈáè„ÄÇ  
ÂØπÊüê‰∏™‰ΩçÁΩÆ $ pos $ ÂíåÁª¥Â∫¶ $ i $ÔºåÂÖ∂ÁºñÁ†ÅÊñπÂºèÂ¶Ç‰∏ãÔºö

$$
\text{PE}_{(pos, 2i)} = \sin\left(\frac{pos}{10000^{2i/d_{model}}}\right)
$$

$$
\text{PE}_{(pos, 2i+1)} = \cos\left(\frac{pos}{10000^{2i/d_{model}}}\right)
$$

- $ pos $ÔºöÂ∫èÂàó‰∏≠ÁöÑ‰ΩçÁΩÆÔºàÁ¨¨Âá†‰∏™ËØçÔºâ
- $ i $ÔºöÁºñÁ†ÅÁª¥Â∫¶ÁöÑÁ¥¢Âºï
- $ d\_{model} $ÔºöÊ®°ÂûãÁöÑÂµåÂÖ•Áª¥Â∫¶ÔºàÂ¶Ç 512Ôºâ

ËøôÁßçËÆæËÆ°ËÆ©ÁºñÁ†ÅÂÖ∑Êúâ‰ª•‰∏ãÁâπÊÄßÔºö

- **Âπ≥ÊªëÂèòÂåñ**ÔºöÁõ∏ÈÇª‰ΩçÁΩÆÁöÑÁºñÁ†ÅÁõ∏‰ººÔºåÊúâÂä©‰∫éÂ≠¶‰π†Â±ÄÈÉ®ÂÖ≥Á≥ª
- **ÂèØ‰ª•Â§ñÊé®**ÔºöÊ®°ÂûãËÉΩÊé®ÂπøÂà∞ÊØîËÆ≠ÁªÉÊó∂Êõ¥ÈïøÁöÑÂ∫èÂàó

# RPE Rotation Positional Encoding

ÊóãËΩ¨‰ΩçÁΩÆÁºñÁ†ÅÔºåÂú® Flux ÁöÑ transformer Ê®°Âùó‰∏≠‰ΩøÁî®Ôºö

```python
class FluxPosEmbed(nn.Module):
  def __init__(self, theta: int, axes_dim: List[int]):
    super().__init__()
    self.theta = theta
    self.axes_dim = axes_dim
  def forward(self, ids: torch.Tensor) -> torch.Tensor:
    n_axes = ids.shape[-1]
    cos_out = []
    sin_out = []
    pos = ids.float()
    for i in range(n_axes):
      cos, sin = get_1d_pos_embed(
        self.axes_dim[i],
        pos[:, i],
        theta=self.theta
        repeat_interleave_real=True,
        use_real=True,
        freqs_dtype = torch.float32
      )
      cos_out.append(cos)
      sin_out.append(sin)
    freqs_cos = torch.cat(cos_out, dim=-1).to(ids.device)
    freqs_sin = torch.cat(sin_out, dim=-1).to(ids.device)
    return freqs_cos, freqs_sin

def get_1d_pos_embed(
    dim: int,
    pos: Union[np.ndarray, int, torch.Tensor],
    theta: float = 10000.0,
    linear_factor=1.0,
    ntk_factor=1.0,
    repeat_interleave_real: bool = True,
    use_real: bool = False,
    freqs_dtype: torch.dtype = torch.float32
) -> Tuple[torch.Tensor, torch.Tensor]:
    """
    Ëé∑Âèñ‰∏ÄÁª¥‰ΩçÁΩÆÁºñÁ†Å
    """
    if isinstance(pos, int):
        pos = torch.arange(pos)
    elif isinstance(pos, np.ndarray):
        pos = torch.from_numpy(pos)

    theta = theta * ntk_factor
    freqs = (
      1.0
      / (theta ** (torch.arange(0, dim, 2, dtype=freqs_dtype, device=pos.device)[:(dim//2)] / dim))
      / linear_factor
    )

    freqs = torch.outer(pos, freqs)
    if use_real and repeat_interleave_real:
      freqs_cos = freqs.cos().repeat_interleave(2, dim=-1, output_size=freqs.shape[1]*2).float()
      freqs_sin = freqs.sin().repeat_interleave(2, dim=-1, output_size=freqs.shape[1]*2).float()
      return freqs_cos, freqs_sin
    elif use_real:
      freqs_cos = torch.cat([freqs.cos(), freqs.cos()], dim=-1).float()
      freqs_sin = torch.cat([freqs.sin(), freqs.sin()], dim=-1).float()
      return freqs_cos, freqs_sin
    else:
      freqs_cis = torch.polar(torch.ones_like(freqs), freqs)
      return freqs_cis
```
